{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Conv2D\n",
    "from tensorflow.keras.layers import BatchNormalization, Activation\n",
    "from tensorflow.keras.layers import AveragePooling2D, Input\n",
    "from tensorflow.keras.layers import Flatten, add\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import os\n",
    "from imutils import paths\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 200\n",
    "data_augmentation = True\n",
    "num_classes = 18\n",
    "subtract_pixel_mean = True\n",
    "n = 3 # number of residual blocks\n",
    "version = 2\n",
    "if version == 1:\n",
    "    depth = n * 6 + 2\n",
    "elif version == 2:\n",
    "    depth = n * 9 + 2\n",
    "\n",
    "model_type = 'ResNet%dv%d' % (depth, version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[INFO] loading images...\nHyundai Verna 1980"
    }
   ],
   "source": [
    "base_path = \"/home/mohit/Desktop/SIH/cars_dataset/SIH\"\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(base_path))\n",
    "data = []\n",
    "labels = []\n",
    "counter = 0\n",
    "# loop over the image paths\n",
    "for imagePath in imagePaths:\n",
    "\t# extract the class label from the filename\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    print(\"\\r\" + label + \" \" + str(counter), end=\"\\r\")\n",
    "    counter+=1\n",
    "    # load the image, convert it to RGB channel ordering, and resize\n",
    "    # it to be a fixed 224x224 pixels, ignoring aspect ratio\n",
    "    try:\n",
    "        image = cv2.imread(imagePath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = cv2.resize(image, (224, 224))\n",
    "        data.append(image)\n",
    "        labels.append(label)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(imagePath)\n",
    "\n",
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "LABELS = np.unique(labels)\n",
    "\n",
    "# perform one-hot encoding on the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partition the data into training and testing splits using 80% of\n",
    "# the data for training and the remaining 20% for testing\n",
    "(x_train, x_test, y_train, y_test) = train_test_split(data, labels,\n",
    "\ttest_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "\n",
    "# define the ImageNet mean subtraction (in RGB order) and set the\n",
    "# the mean subtraction value for each of the data augmentation\n",
    "# objects\n",
    "mean = np.array([123.68, 116.779, 103.939], dtype=\"float32\")\n",
    "trainAug.mean = mean\n",
    "valAug.mean = mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "(1981, 18)\n"
    }
   ],
   "source": [
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "x_train shape: (1584, 224, 224, 3)\n1584 train samples\n397 test samples\ny_train shape: (1584, 18)\ninput shape (224, 224, 3)\n"
    }
   ],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# normalize data.\n",
    "x_train = x_train.astype('float32') / 255\n",
    "x_test = x_test.astype('float32') / 255\n",
    "\n",
    "# if subtract pixel mean is enabled\n",
    "if subtract_pixel_mean:\n",
    "    x_train_mean = np.mean(x_train, axis=0)\n",
    "    x_train -= x_train_mean\n",
    "    x_test -= x_train_mean\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "print(\"input shape\", input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-3\n",
    "    if epoch > 180:\n",
    "        lr *= 0.5e-3\n",
    "    elif epoch > 160:\n",
    "        lr *= 1e-3\n",
    "    elif epoch > 120:\n",
    "        lr *= 1e-2\n",
    "    elif epoch > 80:\n",
    "        lr *= 1e-1\n",
    "    print('Learning rate: ', lr)\n",
    "    return lr\n",
    "\n",
    "    \n",
    "def resnet_layer(inputs,\n",
    "                 num_filters=16,\n",
    "                 kernel_size=3,\n",
    "                 strides=1,\n",
    "                 activation='relu',\n",
    "                 batch_normalization=True,\n",
    "                 conv_first=True):\n",
    "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
    "    Arguments:\n",
    "        inputs (tensor): input tensor from input image or previous layer\n",
    "        num_filters (int): Conv2D number of filters\n",
    "        kernel_size (int): Conv2D square kernel dimensions\n",
    "        strides (int): Conv2D square stride dimensions\n",
    "        activation (string): activation name\n",
    "        batch_normalization (bool): whether to include batch normalization\n",
    "        conv_first (bool): conv-bn-activation (True) or\n",
    "            bn-activation-conv (False)\n",
    "    Returns:\n",
    "        x (tensor): tensor as input to the next layer\n",
    "    \"\"\"\n",
    "    conv = Conv2D(num_filters,\n",
    "                  kernel_size=kernel_size,\n",
    "                  strides=strides,\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal',\n",
    "                  kernel_regularizer=l2(1e-4))\n",
    "\n",
    "    x = inputs\n",
    "    if conv_first:\n",
    "        x = conv(x)\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "    else:\n",
    "        if batch_normalization:\n",
    "            x = BatchNormalization()(x)\n",
    "        if activation is not None:\n",
    "            x = Activation(activation)(x)\n",
    "        x = conv(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def resnet_v1(input_shape, depth, num_classes=num_classes):\n",
    "    \"\"\"ResNet Version 1 Model builder [a]\n",
    "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
    "    Last ReLU is after the shortcut connection.\n",
    "    At the beginning of each stage, the feature map size is halved\n",
    "    (downsampled) by a convolutional layer with strides=2, while \n",
    "    the number of filters is doubled. Within each stage, \n",
    "    the layers have the same number filters and the\n",
    "    same number of filters.\n",
    "    Features maps sizes:\n",
    "    stage 0: 32x32, 16\n",
    "    stage 1: 16x16, 32\n",
    "    stage 2:  8x8,  64\n",
    "    The Number of parameters is approx the same as Table 6 of [a]:\n",
    "    ResNet20 0.27M\n",
    "    ResNet32 0.46M\n",
    "    ResNet44 0.66M\n",
    "    ResNet56 0.85M\n",
    "    ResNet110 1.7M\n",
    "    Arguments:\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    Returns:\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 6 != 0:\n",
    "        raise ValueError('depth should be 6n+2 (eg 20, 32, in [a])')\n",
    "    # start model definition.\n",
    "    num_filters = 16\n",
    "    num_res_blocks = int((depth - 2) / 6)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = resnet_layer(inputs=inputs)\n",
    "    # instantiate the stack of residual units\n",
    "    for stack in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            strides = 1\n",
    "            # first layer but not first stack\n",
    "            if stack > 0 and res_block == 0:  \n",
    "                strides = 2  # downsample\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters,\n",
    "                             strides=strides)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters,\n",
    "                             activation=None)\n",
    "            # first layer but not first stack\n",
    "            if stack > 0 and res_block == 0:\n",
    "                # linear projection residual shortcut\n",
    "                # connection to match changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = add([x, y])\n",
    "            x = Activation('relu')(x)\n",
    "        num_filters *= 2\n",
    "\n",
    "    # add classifier on top.\n",
    "    # v1 does not use BN after last shortcut connection-ReLU\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet_v2(input_shape, depth, num_classes=num_classes):\n",
    "    \"\"\"ResNet Version 2 Model builder [b]\n",
    "    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or \n",
    "    also known as bottleneck layer.\n",
    "    First shortcut connection per layer is 1 x 1 Conv2D.\n",
    "    Second and onwards shortcut connection is identity.\n",
    "    At the beginning of each stage, \n",
    "    the feature map size is halved (downsampled)\n",
    "    by a convolutional layer with strides=2, \n",
    "    while the number of filter maps is\n",
    "    doubled. Within each stage, the layers have \n",
    "    the same number filters and the same filter map sizes.\n",
    "    Features maps sizes:\n",
    "    conv1  : 32x32,  16\n",
    "    stage 0: 32x32,  64\n",
    "    stage 1: 16x16, 128\n",
    "    stage 2:  8x8,  256\n",
    "    Arguments:\n",
    "        input_shape (tensor): shape of input image tensor\n",
    "        depth (int): number of core convolutional layers\n",
    "        num_classes (int): number of classes (CIFAR10 has 10)\n",
    "    Returns:\n",
    "        model (Model): Keras model instance\n",
    "    \"\"\"\n",
    "    if (depth - 2) % 9 != 0:\n",
    "        raise ValueError('depth should be 9n+2 (eg 110 in [b])')\n",
    "    # start model definition.\n",
    "    num_filters_in = 16\n",
    "    num_res_blocks = int((depth - 2) / 9)\n",
    "\n",
    "    inputs = Input(shape=input_shape)\n",
    "    # v2 performs Conv2D with BN-ReLU\n",
    "    # on input before splitting into 2 paths\n",
    "    x = resnet_layer(inputs=inputs,\n",
    "                     num_filters=num_filters_in,\n",
    "                     conv_first=True)\n",
    "\n",
    "    # instantiate the stack of residual units\n",
    "    for stage in range(3):\n",
    "        for res_block in range(num_res_blocks):\n",
    "            activation = 'relu'\n",
    "            batch_normalization = True\n",
    "            strides = 1\n",
    "            if stage == 0:\n",
    "                num_filters_out = num_filters_in * 4\n",
    "                # first layer and first stage\n",
    "                if res_block == 0:  \n",
    "                    activation = None\n",
    "                    batch_normalization = False\n",
    "            else:\n",
    "                num_filters_out = num_filters_in * 2\n",
    "                # first layer but not first stage\n",
    "                if res_block == 0:\n",
    "                    # downsample\n",
    "                    strides = 2 \n",
    "\n",
    "            # bottleneck residual unit\n",
    "            y = resnet_layer(inputs=x,\n",
    "                             num_filters=num_filters_in,\n",
    "                             kernel_size=1,\n",
    "                             strides=strides,\n",
    "                             activation=activation,\n",
    "                             batch_normalization=batch_normalization,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_in,\n",
    "                             conv_first=False)\n",
    "            y = resnet_layer(inputs=y,\n",
    "                             num_filters=num_filters_out,\n",
    "                             kernel_size=1,\n",
    "                             conv_first=False)\n",
    "            if res_block == 0:\n",
    "                # linear projection residual shortcut connection\n",
    "                # to match changed dims\n",
    "                x = resnet_layer(inputs=x,\n",
    "                                 num_filters=num_filters_out,\n",
    "                                 kernel_size=1,\n",
    "                                 strides=strides,\n",
    "                                 activation=None,\n",
    "                                 batch_normalization=False)\n",
    "            x = add([x, y])\n",
    "\n",
    "        num_filters_in = num_filters_out\n",
    "\n",
    "    # add classifier on top.\n",
    "    # v2 has BN-ReLU before Pooling\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=8)(x)\n",
    "    y = Flatten()(x)\n",
    "    outputs = Dense(num_classes,\n",
    "                    activation='softmax',\n",
    "                    kernel_initializer='he_normal')(y)\n",
    "\n",
    "    # instantiate model.\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "         \n__________________________________________________________________________________________________\nbatch_normalization_76 (BatchNo (None, 224, 224, 16) 64          conv2d_84[0][0]                  \n__________________________________________________________________________________________________\nactivation_76 (Activation)      (None, 224, 224, 16) 0           batch_normalization_76[0][0]     \n__________________________________________________________________________________________________\nconv2d_85 (Conv2D)              (None, 224, 224, 16) 2320        activation_76[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_77 (BatchNo (None, 224, 224, 16) 64          conv2d_85[0][0]                  \n__________________________________________________________________________________________________\nactivation_77 (Activation)      (None, 224, 224, 16) 0           batch_normalization_77[0][0]     \n__________________________________________________________________________________________________\nconv2d_87 (Conv2D)              (None, 224, 224, 64) 1088        activation_75[0][0]              \n__________________________________________________________________________________________________\nconv2d_86 (Conv2D)              (None, 224, 224, 64) 1088        activation_77[0][0]              \n__________________________________________________________________________________________________\nadd_27 (Add)                    (None, 224, 224, 64) 0           conv2d_87[0][0]                  \n                                                                 conv2d_86[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_78 (BatchNo (None, 224, 224, 64) 256         add_27[0][0]                     \n__________________________________________________________________________________________________\nactivation_78 (Activation)      (None, 224, 224, 64) 0           batch_normalization_78[0][0]     \n__________________________________________________________________________________________________\nconv2d_88 (Conv2D)              (None, 224, 224, 16) 1040        activation_78[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_79 (BatchNo (None, 224, 224, 16) 64          conv2d_88[0][0]                  \n__________________________________________________________________________________________________\nactivation_79 (Activation)      (None, 224, 224, 16) 0           batch_normalization_79[0][0]     \n__________________________________________________________________________________________________\nconv2d_89 (Conv2D)              (None, 224, 224, 16) 2320        activation_79[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_80 (BatchNo (None, 224, 224, 16) 64          conv2d_89[0][0]                  \n__________________________________________________________________________________________________\nactivation_80 (Activation)      (None, 224, 224, 16) 0           batch_normalization_80[0][0]     \n__________________________________________________________________________________________________\nconv2d_90 (Conv2D)              (None, 224, 224, 64) 1088        activation_80[0][0]              \n__________________________________________________________________________________________________\nadd_28 (Add)                    (None, 224, 224, 64) 0           add_27[0][0]                     \n                                                                 conv2d_90[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_81 (BatchNo (None, 224, 224, 64) 256         add_28[0][0]                     \n__________________________________________________________________________________________________\nactivation_81 (Activation)      (None, 224, 224, 64) 0           batch_normalization_81[0][0]     \n__________________________________________________________________________________________________\nconv2d_91 (Conv2D)              (None, 224, 224, 16) 1040        activation_81[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_82 (BatchNo (None, 224, 224, 16) 64          conv2d_91[0][0]                  \n__________________________________________________________________________________________________\nactivation_82 (Activation)      (None, 224, 224, 16) 0           batch_normalization_82[0][0]     \n__________________________________________________________________________________________________\nconv2d_92 (Conv2D)              (None, 224, 224, 16) 2320        activation_82[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_83 (BatchNo (None, 224, 224, 16) 64          conv2d_92[0][0]                  \n__________________________________________________________________________________________________\nactivation_83 (Activation)      (None, 224, 224, 16) 0           batch_normalization_83[0][0]     \n__________________________________________________________________________________________________\nconv2d_93 (Conv2D)              (None, 224, 224, 64) 1088        activation_83[0][0]              \n__________________________________________________________________________________________________\nadd_29 (Add)                    (None, 224, 224, 64) 0           add_28[0][0]                     \n                                                                 conv2d_93[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_84 (BatchNo (None, 224, 224, 64) 256         add_29[0][0]                     \n__________________________________________________________________________________________________\nactivation_84 (Activation)      (None, 224, 224, 64) 0           batch_normalization_84[0][0]     \n__________________________________________________________________________________________________\nconv2d_94 (Conv2D)              (None, 112, 112, 64) 4160        activation_84[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_85 (BatchNo (None, 112, 112, 64) 256         conv2d_94[0][0]                  \n__________________________________________________________________________________________________\nactivation_85 (Activation)      (None, 112, 112, 64) 0           batch_normalization_85[0][0]     \n__________________________________________________________________________________________________\nconv2d_95 (Conv2D)              (None, 112, 112, 64) 36928       activation_85[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_86 (BatchNo (None, 112, 112, 64) 256         conv2d_95[0][0]                  \n__________________________________________________________________________________________________\nactivation_86 (Activation)      (None, 112, 112, 64) 0           batch_normalization_86[0][0]     \n__________________________________________________________________________________________________\nconv2d_97 (Conv2D)              (None, 112, 112, 128 8320        add_29[0][0]                     \n__________________________________________________________________________________________________\nconv2d_96 (Conv2D)              (None, 112, 112, 128 8320        activation_86[0][0]              \n__________________________________________________________________________________________________\nadd_30 (Add)                    (None, 112, 112, 128 0           conv2d_97[0][0]                  \n                                                                 conv2d_96[0][0]                  \n__________________________________________________________________________________________________\nbatch_normalization_87 (BatchNo (None, 112, 112, 128 512         add_30[0][0]                     \n__________________________________________________________________________________________________\nactivation_87 (Activation)      (None, 112, 112, 128 0           batch_normalization_87[0][0]     \n__________________________________________________________________________________________________\nconv2d_98 (Conv2D)              (None, 112, 112, 64) 8256        activation_87[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_88 (BatchNo (None, 112, 112, 64) 256         conv2d_98[0][0]                  \n__________________________________________________________________________________________________\nactivation_88 (Activation)      (None, 112, 112, 64) 0           batch_normalization_88[0][0]     \n__________________________________________________________________________________________________\nconv2d_99 (Conv2D)              (None, 112, 112, 64) 36928       activation_88[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_89 (BatchNo (None, 112, 112, 64) 256         conv2d_99[0][0]                  \n__________________________________________________________________________________________________\nactivation_89 (Activation)      (None, 112, 112, 64) 0           batch_normalization_89[0][0]     \n__________________________________________________________________________________________________\nconv2d_100 (Conv2D)             (None, 112, 112, 128 8320        activation_89[0][0]              \n__________________________________________________________________________________________________\nadd_31 (Add)                    (None, 112, 112, 128 0           add_30[0][0]                     \n                                                                 conv2d_100[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_90 (BatchNo (None, 112, 112, 128 512         add_31[0][0]                     \n__________________________________________________________________________________________________\nactivation_90 (Activation)      (None, 112, 112, 128 0           batch_normalization_90[0][0]     \n__________________________________________________________________________________________________\nconv2d_101 (Conv2D)             (None, 112, 112, 64) 8256        activation_90[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_91 (BatchNo (None, 112, 112, 64) 256         conv2d_101[0][0]                 \n__________________________________________________________________________________________________\nactivation_91 (Activation)      (None, 112, 112, 64) 0           batch_normalization_91[0][0]     \n__________________________________________________________________________________________________\nconv2d_102 (Conv2D)             (None, 112, 112, 64) 36928       activation_91[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_92 (BatchNo (None, 112, 112, 64) 256         conv2d_102[0][0]                 \n__________________________________________________________________________________________________\nactivation_92 (Activation)      (None, 112, 112, 64) 0           batch_normalization_92[0][0]     \n__________________________________________________________________________________________________\nconv2d_103 (Conv2D)             (None, 112, 112, 128 8320        activation_92[0][0]              \n__________________________________________________________________________________________________\nadd_32 (Add)                    (None, 112, 112, 128 0           add_31[0][0]                     \n                                                                 conv2d_103[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_93 (BatchNo (None, 112, 112, 128 512         add_32[0][0]                     \n__________________________________________________________________________________________________\nactivation_93 (Activation)      (None, 112, 112, 128 0           batch_normalization_93[0][0]     \n__________________________________________________________________________________________________\nconv2d_104 (Conv2D)             (None, 56, 56, 128)  16512       activation_93[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_94 (BatchNo (None, 56, 56, 128)  512         conv2d_104[0][0]                 \n__________________________________________________________________________________________________\nactivation_94 (Activation)      (None, 56, 56, 128)  0           batch_normalization_94[0][0]     \n__________________________________________________________________________________________________\nconv2d_105 (Conv2D)             (None, 56, 56, 128)  147584      activation_94[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_95 (BatchNo (None, 56, 56, 128)  512         conv2d_105[0][0]                 \n__________________________________________________________________________________________________\nactivation_95 (Activation)      (None, 56, 56, 128)  0           batch_normalization_95[0][0]     \n__________________________________________________________________________________________________\nconv2d_107 (Conv2D)             (None, 56, 56, 256)  33024       add_32[0][0]                     \n__________________________________________________________________________________________________\nconv2d_106 (Conv2D)             (None, 56, 56, 256)  33024       activation_95[0][0]              \n__________________________________________________________________________________________________\nadd_33 (Add)                    (None, 56, 56, 256)  0           conv2d_107[0][0]                 \n                                                                 conv2d_106[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_96 (BatchNo (None, 56, 56, 256)  1024        add_33[0][0]                     \n__________________________________________________________________________________________________\nactivation_96 (Activation)      (None, 56, 56, 256)  0           batch_normalization_96[0][0]     \n__________________________________________________________________________________________________\nconv2d_108 (Conv2D)             (None, 56, 56, 128)  32896       activation_96[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_97 (BatchNo (None, 56, 56, 128)  512         conv2d_108[0][0]                 \n__________________________________________________________________________________________________\nactivation_97 (Activation)      (None, 56, 56, 128)  0           batch_normalization_97[0][0]     \n__________________________________________________________________________________________________\nconv2d_109 (Conv2D)             (None, 56, 56, 128)  147584      activation_97[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_98 (BatchNo (None, 56, 56, 128)  512         conv2d_109[0][0]                 \n__________________________________________________________________________________________________\nactivation_98 (Activation)      (None, 56, 56, 128)  0           batch_normalization_98[0][0]     \n__________________________________________________________________________________________________\nconv2d_110 (Conv2D)             (None, 56, 56, 256)  33024       activation_98[0][0]              \n__________________________________________________________________________________________________\nadd_34 (Add)                    (None, 56, 56, 256)  0           add_33[0][0]                     \n                                                                 conv2d_110[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_99 (BatchNo (None, 56, 56, 256)  1024        add_34[0][0]                     \n__________________________________________________________________________________________________\nactivation_99 (Activation)      (None, 56, 56, 256)  0           batch_normalization_99[0][0]     \n__________________________________________________________________________________________________\nconv2d_111 (Conv2D)             (None, 56, 56, 128)  32896       activation_99[0][0]              \n__________________________________________________________________________________________________\nbatch_normalization_100 (BatchN (None, 56, 56, 128)  512         conv2d_111[0][0]                 \n__________________________________________________________________________________________________\nactivation_100 (Activation)     (None, 56, 56, 128)  0           batch_normalization_100[0][0]    \n__________________________________________________________________________________________________\nconv2d_112 (Conv2D)             (None, 56, 56, 128)  147584      activation_100[0][0]             \n__________________________________________________________________________________________________\nbatch_normalization_101 (BatchN (None, 56, 56, 128)  512         conv2d_112[0][0]                 \n__________________________________________________________________________________________________\nactivation_101 (Activation)     (None, 56, 56, 128)  0           batch_normalization_101[0][0]    \n__________________________________________________________________________________________________\nconv2d_113 (Conv2D)             (None, 56, 56, 256)  33024       activation_101[0][0]             \n__________________________________________________________________________________________________\nadd_35 (Add)                    (None, 56, 56, 256)  0           add_34[0][0]                     \n                                                                 conv2d_113[0][0]                 \n__________________________________________________________________________________________________\nbatch_normalization_102 (BatchN (None, 56, 56, 256)  1024        add_35[0][0]                     \n__________________________________________________________________________________________________\nactivation_102 (Activation)     (None, 56, 56, 256)  0           batch_normalization_102[0][0]    \n__________________________________________________________________________________________________\naverage_pooling2d_3 (AveragePoo (None, 7, 7, 256)    0           activation_102[0][0]             \n__________________________________________________________________________________________________\nflatten_3 (Flatten)             (None, 12544)        0           average_pooling2d_3[0][0]        \n__________________________________________________________________________________________________\ndense_3 (Dense)                 (None, 18)           225810      flatten_3[0][0]                  \n==================================================================================================\nTotal params: 1,072,242\nTrainable params: 1,067,026\nNon-trainable params: 5,216\n__________________________________________________________________________________________________\nResNet29v2\n"
    }
   ],
   "source": [
    "if version == 2:\n",
    "    model = resnet_v2(input_shape=input_shape, depth=depth)\n",
    "else:\n",
    "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(lr=lr_schedule(0)),\n",
    "              metrics=['accuracy'])\n",
    "model.summary()\n",
    "plot_model(model, to_file=\"%s.png\" % model_type, show_shapes=True)\n",
    "print(model_type)\n",
    "\n",
    "# prepare model model saving directory.\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'cars18_%s_model.{epoch:03d}.h5' % model_type\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "filepath = os.path.join(save_dir, model_name)\n",
    "\n",
    "# prepare callbacks for model saving and for learning rate adjustment.\n",
    "checkpoint = ModelCheckpoint(filepath=filepath,\n",
    "                             monitor='val_accuracy',\n",
    "                             verbose=1,\n",
    "                             save_best_only=True)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "lr_reducer = ReduceLROnPlateau(factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=5,\n",
    "                               min_lr=0.5e-6)\n",
    "\n",
    "callbacks = [checkpoint, lr_reducer, lr_scheduler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Using real-time data augmentation.\nLearning rate:  0.001\nEpoch 1/200\n"
    },
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": " logits and labels must be broadcastable: logits_size=[32,10] labels_size=[32,18]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits (defined at <ipython-input-49-6505e86b3bed>:39) ]] [Op:__inference_train_function_16453]\n\nFunction call stack:\ntrain_function\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-6505e86b3bed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# fit the model on the batches generated by datagen.flow().\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n\u001b[0m\u001b[1;32m     40\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \"\"\"\n\u001b[1;32m   1464\u001b[0m     \u001b[0m_keras_api_gauge\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit_generator'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m     return self.fit(\n\u001b[0m\u001b[1;32m   1466\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1659\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \"\"\"\n\u001b[0;32m-> 1661\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1662\u001b[0m         (t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    594\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  logits and labels must be broadcastable: logits_size=[32,10] labels_size=[32,18]\n\t [[node categorical_crossentropy/softmax_cross_entropy_with_logits (defined at <ipython-input-49-6505e86b3bed>:39) ]] [Op:__inference_train_function_16453]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True,\n",
    "              callbacks=callbacks)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # this will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        # set input mean to 0 over the dataset\n",
    "        featurewise_center=False,\n",
    "        # set each sample mean to 0\n",
    "        samplewise_center=False,\n",
    "        # divide inputs by std of dataset\n",
    "        featurewise_std_normalization=False,\n",
    "        # divide each input by its std\n",
    "        samplewise_std_normalization=False,\n",
    "        # apply ZCA whitening\n",
    "        zca_whitening=False,\n",
    "        # randomly rotate images in the range (deg 0 to 180)\n",
    "        rotation_range=0,\n",
    "        # randomly shift images horizontally\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically\n",
    "        height_shift_range=0.1,\n",
    "        # randomly flip images\n",
    "        horizontal_flip=True,\n",
    "        # randomly flip images\n",
    "        vertical_flip=False)\n",
    "\n",
    "    # compute quantities required for featurewise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        epochs=epochs, verbose=1, \n",
    "                        steps_per_epoch=len(x_train)//batch_size,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "# score trained model\n",
    "scores = model.evaluate(x_test,\n",
    "                        y_test,\n",
    "                        batch_size=batch_size,\n",
    "                        verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1594058626243",
   "display_name": "Python 3.8.3 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}